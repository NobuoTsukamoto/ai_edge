{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unzip files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -qq ./download/seg_saitama_morning.zip -d download\n",
    "!unzip -qq ./download/seg_tokyo1_day.zip -d download\n",
    "!unzip -qq ./download/seg_tokyo1_morning.zip -d download\n",
    "!unzip -qq ./download/seg_tokyo1_night.zip -d download\n",
    "!unzip -qq ./download/seg_tokyo2_day.zip -d download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ./data/annotations/\n",
    "!mkdir -p ./data/images/\n",
    "!mv ./download/seg_saitama_morning/annotations/* ./data/annotations/\n",
    "!mv ./download/seg_saitama_morning/images/* ./data/images/\n",
    "!mv ./download/seg_tokyo1_day/annotations/* ./data/annotations/\n",
    "!mv ./download/seg_tokyo1_day/images/* ./data/images/\n",
    "!mv ./download/seg_tokyo1_morning/annotations/* ./data/annotations/\n",
    "!mv ./download/seg_tokyo1_morning/images/* ./data/images/\n",
    "!mv ./download/seg_tokyo1_night/annotations/* ./data/annotations/\n",
    "!mv ./download/seg_tokyo1_night/images/* ./data/images/\n",
    "!mv ./download/seg_tokyo2_day/annotations/* ./data/annotations/\n",
    "!mv ./download/seg_tokyo2_day/images/* ./data/images/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf download/__MACOSX\n",
    "!rm -rf download/seg_saitama_morning\n",
    "!rm -rf download/seg_tokyo1_day\n",
    "!rm -rf download/seg_tokyo1_morning\n",
    "!rm -rf download/seg_tokyo1_night\n",
    "!rm -rf download/seg_tokyo2_day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import pathlib\n",
    "import shutil\n",
    "import json\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get started, we would advise you to download all the files, and move them inside the object/data/ folder, so that you have a directory structure like this :\n",
    "\n",
    "```\n",
    "+- data\n",
    "    +- annotations\n",
    "        +- *.jpg\n",
    "    +- images\n",
    "        +- *.jpg\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_IMAGES_DIRECTORY = \"./data/images\"\n",
    "TRAIN_ANNOTATIONS_DIRECTORY = \"./data/annotations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train annotaions files :  2243\n",
      "train images files     :  2243\n"
     ]
    }
   ],
   "source": [
    "train_annotations_files = glob.glob(os.path.join(TRAIN_ANNOTATIONS_DIRECTORY, '*.png'))\n",
    "train_images_files = glob.glob(os.path.join(TRAIN_IMAGES_DIRECTORY, '*.jpg'))\n",
    "\n",
    "train_annotations_files.sort()\n",
    "train_images_files.sort()\n",
    "\n",
    "print('train annotaions files : ', len(train_annotations_files))\n",
    "print('train images files     : ', len(train_images_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "- Horizontal flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2243it [04:19,  8.66it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, path in tqdm(enumerate(train_images_files)):\n",
    "    file_name = os.path.splitext(os.path.basename(path))[0]\n",
    "\n",
    "    # Read image (data).\n",
    "    im = cv2.imread(path)\n",
    "    flip_im = cv2.flip(im, 1) # flip lr\n",
    "    \n",
    "    # Read image (annotation).\n",
    "    annotation_im = cv2.imread(train_annotations_files[i])\n",
    "    flip_annotations_im = cv2.flip(annotation_im, 1) # flip lr\n",
    "    \n",
    "    # Write image (flip lr).\n",
    "    cv2.imwrite(os.path.join(TRAIN_IMAGES_DIRECTORY, file_name + '_flip.jpg'), flip_im)\n",
    "    \n",
    "    # Write image (annotation).\n",
    "    cv2.imwrite(os.path.join(TRAIN_ANNOTATIONS_DIRECTORY, file_name + '_flip.png'), flip_annotations_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train annotaions files :  4486\n",
      "train images files     :  4486\n"
     ]
    }
   ],
   "source": [
    "train_annotations_files = glob.glob(os.path.join(TRAIN_ANNOTATIONS_DIRECTORY, '*.png'))\n",
    "train_images_files = glob.glob(os.path.join(TRAIN_IMAGES_DIRECTORY, '*.jpg'))\n",
    "\n",
    "train_annotations_files.sort()\n",
    "train_images_files.sort()\n",
    "\n",
    "print('train annotaions files : ', len(train_annotations_files))\n",
    "print('train images files     : ', len(train_images_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Category and annotation color label\n",
    "\n",
    "|Category|R|G|B|\n",
    "|:--|--:|--:|--:|\n",
    "|Car|0|0|255|\n",
    "|Bus|193|214|0|\n",
    "|Truck|180|0|129|\n",
    "|SVehicle|255|121|166|\n",
    "|Pedestrian|255|0|0|\n",
    "|Motorbike|65|166|1|\n",
    "|Bicycle|208|149|1|\n",
    "|Signal|255|255|0|\n",
    "|Signs|255|134|0|\n",
    "|Sky|0|152|225|\n",
    "|Building|0|203|151|\n",
    "|Natural|85|255|50|\n",
    "|Wall|92|136|125|\n",
    "|Lane|69|47|142|\n",
    "|Ground|136|45|66|\n",
    "|Sidewalk|0|255|255|\n",
    "|RoadShoulder|215|0|255|\n",
    "|Obstacle|180|131|135|\n",
    "|others|81|99|0|\n",
    "|own|86|62|67|\n",
    "\n",
    "## Pascal VOC color map\n",
    "\n",
    "|Index|Category|\n",
    "|--:|:--|\n",
    "|0|others,own|\n",
    "|1|Car\n",
    "|2|Bus\n",
    "|3|Truck\n",
    "|4|SVehicle\n",
    "|5|Pedestrian\n",
    "|6|Motorbike\n",
    "|7|Bicycle\n",
    "|8|Signal\n",
    "|9|Signs\n",
    "|10|Sky\n",
    "|11|Building\n",
    "|12|Natural\n",
    "|13|Wall\n",
    "|14|Lane\n",
    "|15|Ground\n",
    "|16|Sidewalk\n",
    "|17|RoadShoulder\n",
    "|18|Obstacle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create SegmentationClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dir = os.path.join('./data', 'SegmentationClassRaw')\n",
    "if os.path.isdir(class_dir) == True:\n",
    "    shutil.rmtree(class_dir)\n",
    "os.makedirs(class_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_color_labels = {'Car':[0, 0, 255], 'Bus':[193, 214, 0], 'Truck':[180, 0, 129],\n",
    "                          'SVehicle':[255, 121, 166], 'Pedestrian':[255, 0, 0], 'Motorbike':[65, 166, 1],\n",
    "                          'Bicycle':[208, 149, 1], 'Signal':[255, 255, 0], 'Signs':[255, 134, 0],\n",
    "                          'Sky':[0, 152, 225], 'Building':[0, 203, 151], 'Natural':[85, 255, 50],\n",
    "                          'Wall':[92, 136, 125], 'Lane':[69, 47, 142], 'Ground':[136, 45, 66],\n",
    "                          'Sidewalk':[0, 255, 255], 'RoadShoulder':[215, 0, 255], 'Obstacle':[180, 131, 135],\n",
    "                          'others':[81, 99, 0], 'own':[86, 62, 67]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pascal_voc_color_map = {'others':0, 'own':0, 'Car':1, 'Bus':2, 'Truck':3, 'SVehicle':4, 'Pedestrian':5,\n",
    "                        'Motorbike':6, 'Bicycle':7, 'Signal':8, 'Signs':9, 'Sky':10, 'Building':11,\n",
    "                        'Natural':12, 'Wall':13, 'Lane':14, 'Ground':15, 'Sidewalk':16, 'RoadShoulder':17,\n",
    "                        'Obstacle':18 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4486/4486 [19:33<00:00,  3.82it/s]\n"
     ]
    }
   ],
   "source": [
    "for path in tqdm(train_annotations_files):\n",
    "    basename = os.path.basename(path)\n",
    "    \n",
    "    # Read image.\n",
    "    im = cv2.imread(path)\n",
    "    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    height, width = im.shape[:2]\n",
    "    gray_im = np.zeros((height, width, 1), dtype=np.uint8)\n",
    "    \n",
    "    for label in annotation_color_labels:\n",
    "        color_label = annotation_color_labels[label]\n",
    "        color_map = pascal_voc_color_map[label]\n",
    "        \n",
    "        lower = np.array(color_label)\n",
    "        upper = np.array(color_label)\n",
    "        mask_im = cv2.inRange(im, lower, upper)\n",
    "        \n",
    "        contours, hierarchy = cv2.findContours(mask_im, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        for i in range(len(contours)):\n",
    "            cv2.drawContours(gray_im, contours, -1, (color_map), -1)\n",
    "            cv2.drawContours(gray_im, contours, -1, (255), 1)\n",
    "            \n",
    "            \n",
    "        cv2.imwrite(os.path.join(class_dir, basename), gray_im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data and create train and val txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all 4486 train num 3588  val num 897\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "random.shuffle(train_images_files)\n",
    "num_examples = int(len(train_images_files) * 1.0)\n",
    "num_train = int(0.8 * num_examples)\n",
    "num_val = int(0.2 * num_examples)\n",
    "train_examples = train_images_files[:num_train]\n",
    "val_examples = train_images_files[num_train:num_train+num_val]\n",
    "print('all', num_examples, 'train num', len(train_examples), ' val num', len(val_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_dir = os.path.join('.', 'data', 'ImageSets', 'Segmentation')\n",
    "if os.path.isdir(segmentation_dir) == True:\n",
    "    shutil.rmtree(segmentation_dir)\n",
    "os.makedirs(segmentation_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(os.path.join(segmentation_dir, 'train.txt'), 'w')\n",
    "for i, f in enumerate(train_examples):\n",
    "    file.write(os.path.splitext(os.path.basename(f))[0]+\"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(os.path.join(segmentation_dir, 'val.txt'), 'w')\n",
    "for i, f in enumerate(val_examples):\n",
    "    file.write(os.path.splitext(os.path.basename(f))[0]+\"\\n\")\n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
